{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code was originally used with logbot-audio env\n",
    "# data visualization -> run with venv-umineko-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import seaborn as sns\n",
    "import scipy.io.wavfile\n",
    "# import pyaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "print(librosa.__version__)\n",
    "# palette = sns.color_palette(['#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7', '#000000'])\n",
    "# palette = sns.color_palette([\"#ff4554\", \"#00bbdf\", \"#bad600\", \"#f02d7d\", \"#f8b62e\", \"#8b26a6\",\"#808080\"])\n",
    "# sns.set_palette(palette)\n",
    "palette2 = sns.color_palette([\"#D81B60\", \"#1E88E5\", \"#FFC107\", \"#004D40\"])\n",
    "palette = palette2\n",
    "display(palette)\n",
    "# https://anoiro.com/themes/switch-joycons\n",
    "sns.set_theme(context='paper', style='ticks', palette=palette, font_scale=1.0)\n",
    "color_palette_2 = sns.color_palette('viridis_r', n_colors=10, desat=0.75)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load wav file and Normalize 8bit PCM data between -1 and 1\n",
    "# def load_and_normalize_wav_8bit(audio_path):\n",
    "#     rate, data = scipy.io.wavfile.read(audio_path)\n",
    "\n",
    "#     while len(data) > 30400: # adjust to 3.8000 sec\n",
    "#         data = np.delete(data, len(data)-1)\n",
    "\n",
    "#     # if Stereo, convert it to Mono\n",
    "#     if np.ndim(data) > 1:\n",
    "#         data = data[:, 0] # convert it to mono data\n",
    "#     else:\n",
    "#         data = data\n",
    "    \n",
    "#     # change unsigned int to int\n",
    "#     if min(data) < 0:\n",
    "#         data = data.astype(float)\n",
    "#     else:\n",
    "#         data = data - np.mean(data)\n",
    "\n",
    "#     data_normalized = data / 128 # normalize 8bit PCM data between -1 and 1\n",
    "\n",
    "#     return rate, data_normalized\n",
    "\n",
    "\n",
    "# Load wav file and Normalize 8bit PCM data between -1 and 1\n",
    "# def load_and_normalize_wav_16bit(audio_path):\n",
    "#     rate, data = scipy.io.wavfile.read(audio_path)\n",
    "    \n",
    "#     while len(data) > 33600: # adjust to 4.2000 sec\n",
    "#         data = np.delete(data, len(data)-1)\n",
    "\n",
    "#     # if Stereo, convert it to Mono\n",
    "#     if np.ndim(data) > 1:\n",
    "#         data = data[:, 0] # convert it to mono data\n",
    "#     else:\n",
    "#         data = data\n",
    "    \n",
    "#     # print(np.min(data))\n",
    "#     # print(np.max(data))\n",
    "#     # change unsigned int to int\n",
    "#     if min(data) < 0:\n",
    "#         data = data.astype(float)\n",
    "#     else:\n",
    "#         data = data - np.mean(data)\n",
    "\n",
    "#     data_normalized = data / 32767 # normalize PCM data between -1 and 1\n",
    "\n",
    "#     return rate, data_normalized\n",
    "\n",
    "\n",
    "# https://www.youtube.com/watch?v=rlypsap6Wow\n",
    "# Calculate the amplitude envelope\n",
    "# def amplitude_envelope(signal, frame_length, hop_length):\n",
    "#     amplitude_envelope = []\n",
    "    \n",
    "#     # calculate amplitude envelope for each frame\n",
    "#     for i in range(0, len(signal), hop_length): # if hop_length = 100 -> i = 0, 100, 200, 300, ...\n",
    "#         current_frame_amplitude_envelope = max(signal[i:i+frame_length]) # if frame_length = 200 -> max(signal[0-200]), max(signal[100-300]), max(signal[200-400]), ...\n",
    "#         amplitude_envelope.append(current_frame_amplitude_envelope)\n",
    "    \n",
    "#     return np.array(amplitude_envelope)\n",
    "\n",
    "# # Calculate the amplitude envelope in fancy way\n",
    "# def fancy_amplitude_envelope(signal, frame_length, hop_length):\n",
    "#     return np.array([max(signal[i:i+frame_length]) for i in range(0, signal.size, hop_length)])\n",
    "\n",
    "# https://www.youtube.com/watch?v=EycaSbIRx-0&t=1001s\n",
    "# Calculate RMS Energy\n",
    "def rms (signal, frame_length, hop_length):\n",
    "    rms = []\n",
    "\n",
    "    for i in range(0, len(signal), hop_length):\n",
    "        rms_current_frame = np.sqrt(np.sum(signal[i:i+frame_length]**2) / frame_length)\n",
    "        rms.append(rms_current_frame)\n",
    "\n",
    "    return np.array(rms)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"../audio/\"\n",
    "# dir_name = \"../audio/umineko-2024/\"\n",
    "\n",
    "audio_sec = 4.2\n",
    "\n",
    "# hayabusa_file = f\"hayabusa_nr_amp4_{audio_sec}s\"\n",
    "# noise_file = f\"noise_amp4_{audio_sec}s\"\n",
    "\n",
    "hayabusa_file = f\"_hayabusa\"\n",
    "noise_file = f\"_noise\"\n",
    "\n",
    "hayabusa_path = os.path.join(dir_name, hayabusa_file + \".wav\")\n",
    "print(hayabusa_path)\n",
    "noise_path = os.path.join(dir_name, noise_file + \".wav\")\n",
    "print(noise_path)\n",
    "\n",
    "print(f\"Loading WAV file... : {hayabusa_path}\")\n",
    "# rate, hayabusa = load_and_normalize_wav_8bit(audio_path=hayabusa_path)\n",
    "# sampling_rate, hayabusa_data = load_and_normalize_wav_16bit(audio_path=hayabusa_path)\n",
    "hayabusa_data, sampling_rate = librosa.load(hayabusa_path, sr=None) # load with original sampling rate\n",
    "\n",
    "print(hayabusa_data[:5])\n",
    "print(f\"sampling rate: {sampling_rate}\")\n",
    "print(f\"Length: {len(hayabusa_data)}\")\n",
    "print(f\"Min: {np.min(hayabusa_data)}\")\n",
    "print(f\"Max: {np.max(hayabusa_data)}\")\n",
    "print(np.max(hayabusa_data))\n",
    "print(f\"------------------------------------------------------------------\")\n",
    "print(f\"Loading WAV file... : {noise_path}\")\n",
    "# rate, noise = load_and_normalize_wav_8bit(audio_path=noise_path)\n",
    "# sampling_rate, noise_data = load_and_normalize_wav_16bit(audio_path=noise_path)\n",
    "noise_data, sampling_rate = librosa.load(noise_path, sr=None) # load with original sampling rate\n",
    "print(noise_data[:5])\n",
    "print(f\"sampling rate: {sampling_rate}\")\n",
    "print(f\"Length: {len(noise_data)}\")\n",
    "print(f\"Min: {np.min(noise_data)}\")\n",
    "print(f\"Max: {np.max(noise_data)}\")\n",
    "print(f\"------------------------------------------------------------------\")\n",
    "print(f\"Time:\")\n",
    "time = np.arange(0, hayabusa_data.shape[0]/sampling_rate, 1/sampling_rate) # get time to plot\n",
    "print(time[:5])\n",
    "print(len(time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AE & RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_save_dir = \"../figure/umineko-2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_LENGTH = 200\n",
    "HOP_LENGTH = 100\n",
    "\n",
    "# Amplitude Envelope\n",
    "# ae_hayabusa = amplitude_envelope(signal=hayabusa_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "# ae_noise = amplitude_envelope(signal=noise_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "# RMS Energy\n",
    "# rms_hayabusa = rms(signal=hayabusa_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "# rms_noise = rms(signal=noise_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "\n",
    "_rms_hayabusa = librosa.feature.rms(y=hayabusa_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH, center=True)\n",
    "_rms_noise = librosa.feature.rms(y=noise_data, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH, center=True)\n",
    "\n",
    "# print(rms_hayabusa.shape)\n",
    "# print(_rms_hayabusa[0, :].shape)\n",
    "# print(np.sum(rms_hayabusa - _rms_hayabusa[0, 1:]))\n",
    "\n",
    "rms_hayabusa = _rms_hayabusa[0, :]\n",
    "rms_noise = _rms_noise[0, :]\n",
    "\n",
    "# transform frame to time domain\n",
    "frames = range(len(rms_hayabusa))\n",
    "t = librosa.frames_to_time(frames=frames, sr=sampling_rate, hop_length=HOP_LENGTH)\n",
    "# print(f\"Hayabusa\")\n",
    "describe_hayabusa = pd.DataFrame(rms_hayabusa).describe()\n",
    "# display(describe_hayabusa)\n",
    "\n",
    "# print(f\"Noise\")\n",
    "describe_noise = pd.DataFrame(rms_noise).describe()\n",
    "# display(describe_noise)\n",
    "\n",
    "# plot\n",
    "gridspec_kw={\n",
    "    # 'width_ratios': [1, 1],\n",
    "    'wspace': 0.1,\n",
    "    'hspace': 0.8}\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 6), gridspec_kw=gridspec_kw)\n",
    "ax0, ax1 = axes.flatten()\n",
    "ax_list = [ax0, ax1]\n",
    "rms_list = [rms_hayabusa, rms_noise]\n",
    "title_list = [\"Falcon\", \"Noise\"]\n",
    "y_lim_list = [100, 100]\n",
    "mean_list = [np.mean(rms_hayabusa), np.mean(rms_noise)]\n",
    "median_list = [np.median(rms_hayabusa), np.median(rms_noise)]\n",
    "bins_list = [30, 10]\n",
    "for i, ax in enumerate(ax_list):\n",
    "    ax = sns.histplot(ax=ax, x=rms_list[i], color=palette[1], bins=bins_list[i], alpha=0.75)\n",
    "    # ax = plt.hist(y_list[i], bins=30, alpha=0.8)\n",
    "    ax.set_ylim(0, y_lim_list[i])\n",
    "    ax.set_xlim(0.0, 0.65)\n",
    "    ax.set_title(title_list[i], pad=10)\n",
    "    ax.set_xlabel(\"RMS Energy\", labelpad=10)\n",
    "    ax.set_ylabel(\"Frequency\", labelpad=10)\n",
    "    ax.axvline(x=mean_list[i], linewidth=2, label=\"Mean\", color=\"black\")\n",
    "    ax.text(x=0.25, y=70, s=f\"Mean RMS Energy= {mean_list[i]:.5f}\", fontsize=14)\n",
    "    # ax.axvline(x=median_list[i], linewidth=2, label=\"Median\", color=\"black\")\n",
    "    # ax.text(x=0.25, y=70, s=f\"Median RMS Energy= {mean_list[i]:.5f}\")\n",
    "    ax.grid(which='major')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# fig.savefig(f\"{fig_save_dir}/00_comparison_01.png\", dpi=600)\n",
    "# fig.savefig(f\"{fig_save_dir}/00_comparison_01.svg\", dpi=600)\n",
    "# ---------------------------------------------------------------------\n",
    "# pv = 10 に設定してから再生しているので、\n",
    "# 厳密には再生された音を録音してその音の強さを比較しないといけない？\n",
    "# ここでのスペック上の音の強さと実際に鳴った音は違う？\n",
    "# pv = 10 のとき、ラベラーさん的には hayabusa_42_nr_amp3.mp4 が\n",
    "# もっともクリアで、良く聴こえたようだった（私も同じ感覚だった）\n",
    "# また、 noise_42_amp3 はhayabusa_42_nr_amp3よりも少し音が小さく感じた\n",
    "# hayabusa_42_nr_amp3 と noise_42_amp4 を pv=10で再生して\n",
    "# それを比較すべし（大きなズレがなければ良いはず...）\n",
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "def plot_spectrogram(ax, data, rate, ax_title):\n",
    "    # fft frame size\n",
    "    fft_size = 2**8\n",
    "    # frame shift length\n",
    "    hop_length = int(fft_size / 4)  \n",
    "    # Short-time Foulier Transformation\n",
    "    amplitude = np.abs(librosa.core.stft(data, n_fft=fft_size, hop_length=hop_length))\n",
    "    # Amplitude to db\n",
    "    log_power = librosa.core.amplitude_to_db(amplitude, ref=np.max)\n",
    "    # librosa.display.specshow(log_power, sr=rate, hop_length=hop_length, x_axis='time', y_axis='hz', cmap='magma')\n",
    "    img = librosa.display.specshow(log_power, sr=rate, hop_length=hop_length, x_axis='time', y_axis='hz', cmap='viridis', ax=ax)\n",
    "    # plt.colorbar(format='%+2.0f dB', ax=ax)\n",
    "    ax.set_title(ax_title.replace(\"_\", \" \"), pad=10, fontsize=24, fontweight='bold')\n",
    "    ax.set_xlabel(\"Time [s]\", labelpad=5)\n",
    "    ax.set_ylabel(\"Frequency [Hz]\",  labelpad=10)\n",
    "    ax.set_xticks(np.arange(0, 5, 1))\n",
    "    ax.set_xlim(0.0, 4.20)\n",
    "    ax.set_yticks(np.arange(0, 5000, 1000))\n",
    "    ax.set_ylim(0.0, 4000)\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(tck.FuncFormatter(lambda x,_: f'{x:.1f}'))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "GRIDSPEC_KW={\n",
    "    'width_ratios': [1, 1],\n",
    "    'wspace': 0.4,\n",
    "    'hspace': 0.6\n",
    "}\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5), gridspec_kw=GRIDSPEC_KW)\n",
    "ax0, ax1, ax2, ax3 = axes.flatten()\n",
    "ax_list = [ax0, ax1, ax2, ax3]\n",
    "signal_list = [hayabusa_data, hayabusa_data, noise_data, noise_data]\n",
    "# ae_list = [ae_hayabusa, ae_noise]\n",
    "rms_list = [rms_hayabusa, rms_hayabusa, rms_noise, rms_noise]\n",
    "title_list = [f\"Predator\", f\"Predator\", f\"Noise\", f\"Noise\"]\n",
    "mean_y_jitter_list = [0.90] * 4\n",
    "plt.rcParams['legend.handlelength'] = 1.2\n",
    "for i, ax in enumerate(ax_list):\n",
    "    ax = ax_list[i]\n",
    "    if i == 0 or i == 2:\n",
    "        # ax = sns.lineplot(ax=ax, x=time, y=signal_list[i], linewidth=1.0, color=\"#333333\", alpha=0.5, label=\"Signal\")\n",
    "        # ax = sns.lineplot(ax=ax, x=t, y=rms_list[i], linewidth=3, color=palette[2], alpha=0.9, label=\"RMS\")\n",
    "        ax.plot(time, signal_list[i], linewidth=1.0, color=\"#333333\", alpha=0.5, label=\"Signal\")\n",
    "        ax.plot(t, rms_list[i], linewidth=2, color=palette[2], alpha=0.9, label=\"RMS\")\n",
    "        ax.axhline(y=np.mean(rms_list[i]), xmin=0.0, xmax=4.2, linewidth=2, linestyle=\"-\", color=palette[1], alpha=0.9)\n",
    "        ax.set_xlim(-0.15, 4.35)\n",
    "        ax.set_yticks(np.arange(-1, 1.1, 1.0))\n",
    "        ax.set_ylim(-1.5, 1.5)\n",
    "        ax.yaxis.set_major_formatter(\"{:.1f}\".format)\n",
    "        ax.set_xlabel(\"Time [s]\", labelpad=5)\n",
    "        ax.set_ylabel(\"Amplitude\", labelpad=10)\n",
    "        ax.text(x=0.10, y=np.mean(rms_list[i])+mean_y_jitter_list[i], size=8, fontweight='bold', s=f\"Mean RMS = {np.mean(rms_list[i]):.5f}\", color=palette[1])\n",
    "        legend = ax.legend(loc=\"lower right\", ncol=3, fontsize=8)\n",
    "        for line in legend.get_lines():\n",
    "            line.set_linewidth(1.0)  # 凡例の線の太さを設定\n",
    "        ax.grid(which='major', alpha=0.3)\n",
    "    \n",
    "    elif i == 1:\n",
    "        img0 = plot_spectrogram(ax=ax, data=hayabusa_data, rate=sampling_rate, ax_title=title_list[i])\n",
    "        fig.colorbar(img0, ax=ax, format=\"%+2.f dB\")\n",
    "    elif i == 3:\n",
    "        img1 = plot_spectrogram(ax=ax, data=noise_data, rate=sampling_rate, ax_title=title_list[i])\n",
    "        fig.colorbar(img1, ax=ax, format=\"%+2.f dB\")\n",
    "    \n",
    "    ax.set_title(title_list[i], pad=5, fontsize=12, fontweight='bold')\n",
    "\n",
    "    # if i < 2:\n",
    "    #     ax.set_xlabel('')\n",
    "    # cbar = fig.colorbar(img0, ax=[ax1, ax3], format=\"%+2.f dB\")\n",
    "        \n",
    "    # if i == 0 or i == 1:\n",
    "    #     ax.set_xlabel(\"\", labelpad=10)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.text(-0.22, 1.2, '(a)', transform=ax.transAxes, fontsize=12, fontweight='bold', va='top', ha='right')\n",
    "    elif i == 2:\n",
    "        ax.text(-0.22, 1.2, '(b)', transform=ax.transAxes, fontsize=12, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.close()\n",
    "\n",
    "save_dir = f\"../output/figure-for-paper\"\n",
    "fig.savefig(f\"{save_dir}/png/fig_s02_audio.png\", dpi=350, bbox_inches='tight', pad_inches=0.2, transparent=False)\n",
    "fig.savefig(f\"{save_dir}/pdf/fig_s02_audio.pdf\", dpi=600, bbox_inches='tight', pad_inches=0.2, transparent=False)\n",
    "# fig.savefig(f\"{save_dir}/figure/fig_s02_audio.svg\", dpi=600, bbox_inches='tight', pad_inches=0.1, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration of 1 sample\n",
    "sample_duration = 1 / sampling_rate\n",
    "print(f\"Duration of 1 sample is: {sample_duration: .6f} seconds\")\n",
    "\n",
    "# Duration of the audio signal in seconds\n",
    "duration = sample_duration * len(hayabusa_data)\n",
    "print(f\"Duration of signal is: {duration:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT (Fast Foulier Trasnformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Amplitude plot\n",
    "def plot_freqency_amplitude(ax, data, rate, file_name):\n",
    "    # FFT (Fast Fourier transform) : Time domain to Frequency Domain\n",
    "    SAMPLING_RATE = 8000\n",
    "    signal = data\n",
    "    # fft_data = np.abs(np.fft.fft(data))\n",
    "    F = np.fft.fft(signal)\n",
    "    F_abs = np.abs(F)\n",
    "    F_abs_amp = F_abs / SAMPLING_RATE * 2 # normalize\n",
    "    F_abs_amp[0] = F_abs_amp[0] / 2\n",
    "    F_abs_amp[0] = 0\n",
    "    fft_data = F_abs_amp\n",
    "    nyquist_frequency = int(SAMPLING_RATE/2)\n",
    "    # Frequency\n",
    "    freqList = np.fft.fftfreq(data.shape[0], d=1.0/rate)  \n",
    "    # plot\n",
    "\n",
    "    # print(freqList)\n",
    "    # print(fft_data)\n",
    "    sns.lineplot(x=freqList, y=fft_data, ax=ax)\n",
    "    # ax.set_xlim(0, rate/2) # show only 0 ～ 4000Hz\n",
    "    ax.set_xlim(400, 4000)\n",
    "    ax.set_ylim(0, 0.11)\n",
    "    ax.set_title(file_name.replace(\"_\", \" \"), fontsize=18, pad=10)\n",
    "    ax.set_xlabel(\"Frequency [Hz]\", fontsize=16, labelpad=10)\n",
    "    ax.set_ylabel(\"Amplitude\", fontsize=16, labelpad=10)\n",
    "    # ax.grid(which='major')\n",
    "    \n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "GRIDSPEC_KW = {\n",
    "    # 'width_ratios': [1,1],\n",
    "    'height_ratios': [1,1], \n",
    "    'wspace': 0.1, \n",
    "    'hspace': 0.5\n",
    "}\n",
    "fig, (ax0, ax1) = plt.subplots(2, 1, figsize=(9, 10), gridspec_kw=GRIDSPEC_KW)\n",
    "# Hayabusa\n",
    "plot_freqency_amplitude(ax=ax0, data=hayabusa_data, rate=sampling_rate, file_name=hayabusa_file)\n",
    "# Noise\n",
    "plot_freqency_amplitude(ax=ax1, data=noise_data, rate=sampling_rate, file_name=noise_file)\n",
    "ax0.set_xscale('log')\n",
    "ax1.set_xscale('log')\n",
    "ax0.grid()\n",
    "ax1.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams.update({'font.size': 16})\n",
    "GRIDSPEC_KW = {\n",
    "    # 'width_ratios': [1,1],\n",
    "    # 'height_ratios': [1,1], \n",
    "    'wspace': 0.5, \n",
    "    'hspace': 0.1\n",
    "}\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 4), gridspec_kw=GRIDSPEC_KW)\n",
    "# Hayabusa\n",
    "img0 = plot_spectrogram(ax=ax0, data=hayabusa_data, rate=sampling_rate, ax_title=\"Predator\")\n",
    "# Noise\n",
    "img1 = plot_spectrogram(ax=ax1, data=noise_data, rate=sampling_rate, ax_title=\"Noise\")\n",
    "# fig.colorbar(img0, ax=[ax0, ax1], format=\"%+2.f dB\") # common colorbar\n",
    "# fig.colorbar(img0, ax=ax0, format=\"%+2.f dB\")\n",
    "# fig.colorbar(img1, ax=ax1, format=\"%+2.f dB\")\n",
    "# Add a common colorbar\n",
    "cbar = fig.colorbar(img0, ax=[ax0, ax1], format=\"%+2.f dB\")\n",
    "# cbar.set_label('Amplitude [dB]', fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sound_check')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ccd2c1b07e60751f4f180b30dbbcb987cfd60c85b25ab62ddc84a89c699d3f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
