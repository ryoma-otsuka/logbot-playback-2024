{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Playback and Acceleration Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import seaborn as sns\n",
    "palette2 = sns.color_palette([\"#D81B60\", \"#1E88E5\", \"#FFC107\", \"#004D40\"])\n",
    "palette = palette2\n",
    "sns.set_theme(context='poster', style='ticks', palette=palette, font_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_for_zure_test(df):\n",
    "    df.insert(len(df.columns), 'speaker_on_ffill', df['speaker_on'].ffill(inplace=False))\n",
    "    df.insert(len(df.columns), 'play_audio_zero_fill', df['play_audio'].fillna(0))\n",
    "    df.insert(len(df.columns), '_index', np.arange(0, len(df), 1))\n",
    "    return df\n",
    "\n",
    "def detect_acceleration_sensor_data_response(df, threshold=0.2):\n",
    "    '''\n",
    "    Very simple change point detection algorithm using a threshold value\n",
    "    '''\n",
    "    acc_x = df['acc_x'].values\n",
    "    acc_y = df['acc_y'].values\n",
    "    acc_z = df['acc_z'].values\n",
    "    for i in range(1, len(df)+1, 1):\n",
    "        acc_x_diff = np.abs(acc_x[i] - acc_x[i-1])\n",
    "        acc_y_diff = np.abs(acc_y[i] - acc_y[i-1])\n",
    "        acc_z_diff = np.abs(acc_z[i] - acc_z[i-1])\n",
    "        total_abs_diff = acc_x_diff + acc_y_diff + acc_z_diff\n",
    "        if total_abs_diff > threshold:\n",
    "            return df.index[i], i # index in the df, and i\n",
    "    return 0, 0\n",
    "\n",
    "\n",
    "def plot_acc_and_speaker_data_for_zure_test(df, idx_from, idx_to, detection=False):\n",
    "    df = df[idx_from:idx_to]\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "    ax = sns.lineplot(ax=ax, x='_index', y='acc_x', data=df, color=palette[0], label=\"x\")\n",
    "    ax = sns.lineplot(ax=ax, x='_index', y='acc_y', data=df, color=palette[2], label=\"y\")\n",
    "    ax = sns.lineplot(ax=ax, x='_index', y='acc_z', data=df, color=palette[1], label=\"z\")\n",
    "    ax.set_ylabel('Acc (g)')\n",
    "    ax.set_ylim(-2.2, 2.2)\n",
    "    ax.grid(which='major')\n",
    "    ax.legend(ncol=3, loc=\"lower right\")\n",
    "    change_indices = df.index[(df['speaker_on_ffill'].shift(1) == 0) & (df['speaker_on_ffill'] == 1)].tolist()\n",
    "    for idx in change_indices:\n",
    "        ax.axvline(x=idx, color='black', linestyle='--')\n",
    "        ax.axvspan(xmin=idx, xmax=idx+25*4.2, color='grey', alpha=0.3)\n",
    "        ax.axvline(x=idx+3, color='black', linestyle='-') # shift 120 ms (40 ms * 3 samples) \n",
    "        ax.axvspan(xmin=idx+3, xmax=idx+3+25*4.2, color='grey', alpha=0.3)\n",
    "    ax.set_xlim(idx_from, idx_to)\n",
    "    ax.set_xlabel('t (data point)')\n",
    "    ax.set_ylabel('Acc (g)')\n",
    "\n",
    "    if detection == True:\n",
    "        THRESHOLD = 0.2\n",
    "        response_idx, _i = detect_acceleration_sensor_data_response(df, threshold=THRESHOLD)\n",
    "        ax.axvline(x=response_idx, color='green', linestyle='-')\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "    return fig, df, change_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the path appropriately\n",
    "# base_dir = \"../path_to_base_dir\"\n",
    "base_dir = \"C:/Users/ryoma/D/logbot-data/umineko/Umineko2024/v5-umineko-2024-playback/v5-spk-acc-zure-test/experiment-data\"\n",
    "\n",
    "input_path = f\"{base_dir}/device-03/trial-01/logdata/logdata.csv\" # 11 trials\n",
    "path1 = input_path\n",
    "\n",
    "input_path = f\"{base_dir}/device-04/trial-01/logdata/logdata.csv\" # 8 trials\n",
    "path2 = input_path\n",
    "path_list = [path1, path2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET_VALUE_MS = 338\n",
    "device_list = []\n",
    "trial_list = []\n",
    "playback_count_list = []\n",
    "idx_diff_list = []\n",
    "time_diff_ms_list = []\n",
    "time_delay_ms_list = []\n",
    "for p, path in enumerate(path_list):\n",
    "    print(f\"input_path: {path}\")\n",
    "    device = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(path))))\n",
    "    trial = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "    df = pd.read_csv(path)\n",
    "    df = process_df_for_zure_test(df)\n",
    "    fig, _df, playback_indices = plot_acc_and_speaker_data_for_zure_test(df, 0, len(df))\n",
    "    print(f\"playback_indices: {playback_indices}\")\n",
    "\n",
    "    for i in range(0, len(playback_indices), 1):\n",
    "        idx = playback_indices[i]\n",
    "        fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=idx-1, idx_to=idx+30+1, detection=True)\n",
    "        response_idx, _i = detect_acceleration_sensor_data_response(_df, threshold=0.2)\n",
    "        idx_diff = response_idx - idx\n",
    "        time_diff_ms = idx_diff * 1000 / 25\n",
    "        print(f\"playback: {i+1}\")\n",
    "        print(f\"idx = {idx} | response_idx: {response_idx} | i: {_i}\")\n",
    "        print(f\"idx_diff = {idx_diff} | diff (ms): {time_diff_ms}\")\n",
    "\n",
    "        device_list.append(device)\n",
    "        trial_list.append(trial)\n",
    "        playback_count_list.append(i)\n",
    "        idx_diff_list.append(idx_diff)\n",
    "        time_diff_ms_list.append(time_diff_ms)\n",
    "        time_delay_ms_list.append(time_diff_ms - OFFSET_VALUE_MS)\n",
    "\n",
    "data_dict = {\n",
    "    'device': device_list,\n",
    "    'trial': trial_list,\n",
    "    'playback_count': playback_count_list,\n",
    "    'idx_diff': idx_diff_list,\n",
    "    'time_diff': time_diff_ms_list, # ms\n",
    "    'time_delay': time_delay_ms_list # ms\n",
    "}\n",
    "df_results = pd.DataFrame(data_dict)\n",
    "\n",
    "# black lines: playback timing\n",
    "# green lines: detected change points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. S05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(558)\n",
    "\n",
    "df = df_results\n",
    "# y_colname = 'time_diff'\n",
    "y_colname = 'time_delay'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "median = np.median(df[y_colname])\n",
    "min = np.min(df[y_colname])\n",
    "max = np.max(df[y_colname])\n",
    "\n",
    "ax.axhline(xmin=0, xmax=10, y=max, color=palette[0], linestyle='-',    label=f'max      = {max:.2f}')\n",
    "ax.axhline(xmin=0, xmax=10, y=median, color=palette[1], linestyle=\"-\", label=f'median = {median:.2f}')\n",
    "ax.axhline(xmin=0, xmax=10, y=min, color=palette[2], linestyle='-',    label=f'min       = {min:.2f}')\n",
    "\n",
    "ax.yaxis.set_minor_locator(tck.MultipleLocator(50))\n",
    "ax.grid(which='minor', axis='y', linestyle='-', linewidth='0.75')\n",
    "ax.grid(which='major', axis='y', linestyle='-', linewidth='0.75')\n",
    "\n",
    "# Violin plot\n",
    "violin_parts = sns.violinplot(\n",
    "    x='device', y=y_colname, data=df, \n",
    "    inner=None,\n",
    "    linewidth=0.0, color='#333333', saturation=0.5,\n",
    "    ax=ax\n",
    ")\n",
    "for pc in violin_parts.collections:\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_facecolor('#333333')\n",
    "    pc.set_alpha(0.25)\n",
    "\n",
    "# Box plot\n",
    "unique_devices = df['device'].unique()\n",
    "device_positions = np.arange(len(unique_devices)) + 0.25  # shift 0.25 to right\n",
    "data_by_device = [df[df['device'] == device][y_colname] for device in unique_devices]\n",
    "\n",
    "box_parts = ax.boxplot(\n",
    "    data_by_device,\n",
    "    positions=device_positions,\n",
    "    widths=0.15,\n",
    "    patch_artist=True,\n",
    "    medianprops=dict(color='black', linewidth=3.0),\n",
    "    whiskerprops=dict(color='black', linewidth=2.0),\n",
    "    capprops=dict(color='black', linewidth=2.0),\n",
    "    boxprops=dict(facecolor='white', color='black', linewidth=2.0),\n",
    ")\n",
    "\n",
    "ax.set_xticks(np.arange(len(unique_devices)))\n",
    "ax.set_xticklabels(unique_devices)\n",
    "\n",
    "np.random.seed(558)\n",
    "sns.stripplot(x='device', y=y_colname, data=df, color=\"#333333\", jitter=True, size=9, alpha=0.7, ax=ax)\n",
    "ax.set_yticks(np.arange(0, 1300, 100))\n",
    "\n",
    "if y_colname == 'time_diff':\n",
    "    ax.set_ylim(410, 1240)\n",
    "elif y_colname == 'time_delay':\n",
    "    ax.set_ylim(110, 890)\n",
    "\n",
    "plt.legend(ncol=1)\n",
    "plt.xlabel('Device', labelpad=10)\n",
    "plt.ylabel('Time difference (ms)', labelpad=10)\n",
    "plt.show()\n",
    "save_dir = \"../output/figure-for-paper/\"\n",
    "# fig.savefig(f\"{save_dir}/png/fig_s05_zure_spk_command_audio_time_diff.png\", dpi=350, bbox_inches=\"tight\", pad_inches=0.25, transparent=False)\n",
    "# fig.savefig(f\"{save_dir}/pdf/fig_s05_zure_spk_command_audio_time_diff.pdf\", dpi=600, bbox_inches=\"tight\", pad_inches=0.25, transparent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_path)\n",
    "df = process_df_for_zure_test(df)\n",
    "fig, _df, playback_indices = plot_acc_and_speaker_data_for_zure_test(df, 0, len(df))\n",
    "print(f\"playback_indices: {playback_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=1500, idx_to=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the first trial\n",
    "# the index range should cover the entire first trial\n",
    "fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=1475, idx_to=2200) \n",
    "# print(_df.columns)\n",
    "show_columns = [\n",
    "    'rtc_year', 'rtc_month', 'rtc_day', 'rtc_hour', 'rtc_min', 'rtc_sec', 'rtc_msec',\n",
    "    'camera_command', 'camera_recording', 'camera_count', 'play_audio', 'speaker_on', 'audio_file']\n",
    "df_show = _df[_df['rtc_msec'] == 0][show_columns]\n",
    "print(f\"camera_command: {np.sum(df_show['camera_command'])}\")     # recording time +1 (sec)\n",
    "print(f\"camera_recording: {np.sum(df_show['camera_recording'])}\") # recording time (sec)\n",
    "display(df_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look\n",
    "fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=1775, idx_to=1950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much closer look\n",
    "fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=1800-1, idx_to=1830+1)\n",
    "# fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=1800-1, idx_to=1830+1, detection=True)\n",
    "# -> in this trial, the acceleration signal changed around the index 1816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the change point detection algorithm to the first trial\n",
    "print(playback_indices)\n",
    "for i in range(0, len(playback_indices[:3]), 1):\n",
    "    idx = playback_indices[i]\n",
    "    fig, _df, _ = plot_acc_and_speaker_data_for_zure_test(df, idx_from=idx-1, idx_to=idx+30+1, detection=True)\n",
    "    response_idx, _i = detect_acceleration_sensor_data_response(_df, threshold=0.2)\n",
    "    idx_diff = response_idx - idx\n",
    "    print(f\"playback: {i+1}\")\n",
    "    print(f\"idx = {idx} | response_idx: {response_idx} | i: {_i}\")\n",
    "    print(f\"idx_diff = {idx_diff} | diff (ms): {idx_diff * 40}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(_df[['_index', 'acc_x', 'acc_y', 'acc_z']].head(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how different threshold values influence the results\n",
    "threshold_list = [0.1, 0.2, 0.3, 0.5, 1.0]\n",
    "for t, threshold in enumerate(threshold_list):\n",
    "    response_idx, _i = detect_acceleration_sensor_data_response(_df, threshold=threshold)\n",
    "    print(f\"threshold = {threshold} | response_idx: {response_idx} | i: {_i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_delay_time_ms(delay_sample_count, t_command, t_humna_aud_res, t_acc_res):\n",
    "    t_total_response = delay_sample_count / 25 * 1000 # 25 Hz\n",
    "    t_delay_time_ms = t_total_response - t_command - t_humna_aud_res - t_acc_res\n",
    "    return t_delay_time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_delay_time_ms = calc_delay_time_ms(16, 120, 228, 0)\n",
    "print(f\"{t_delay_time_ms} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{1000 * 16/25} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umineko-analysis-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
